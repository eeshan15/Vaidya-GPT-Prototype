{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG MODEL FOR ONE SINGLE BOOK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader(\"data\\Medical_book.pdf\")\n",
    "data = loader.load()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "637"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  3424\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data)\n",
    "print(\"Total number of documents: \",len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05168594419956207,\n",
       " -0.030764883384108543,\n",
       " -0.03062233328819275,\n",
       " -0.02802734263241291,\n",
       " 0.01813093200325966]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() \n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector = embeddings.embed_query(\"hello, world!\")\n",
    "vector[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=docs, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstore.as_retriever(search_type=\"similarity\",search_kwargs={\"k\":10})\n",
    "retrieved_docs=retriever.invoke(\"how cough forms?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "progress to the life-threatening disease emphysema.\n",
      "A mild cough, sometimes called smokers’ cough, is\n",
      "usually the first visible sign of chronic bronchitis.\n",
      "Coughing brings up phlegm, although the amount varies\n",
      "considerably from person to person. Wheezing and\n",
      "shortness of breathmay accompany the cough. Diag-\n",
      "nostic tests show a decrease in lung function. As the dis-\n",
      "ease advances, breathing becomes difficult and activity\n",
      "decreases. The body does not get enough oxygen, lead-\n",
      "ing to changes in the composition of the blood.\n",
      "Diagnosis\n",
      "Initial diagnosis of bronchitis is based on observing\n",
      "the patient’s symptoms and health history. The physician\n",
      "will listen to the patient’s chest with a stethoscope for\n",
      "specific sounds that indicate lung inflammation, such as\n",
      "moist rales and crackling, and wheezing, that indicates\n",
      "airway narrowing. Moist rales is a bubbling sound heard\n",
      "with a stethoscope that is caused by fluid secretion in the\n",
      "bronchial tubes.\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[5].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "llm=ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\",temperature=0.1,max_tokens=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",system_prompt),\n",
    "        (\"human\",\"{input}\"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESPONSE FROM THE SOURCE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain=create_stuff_documents_chain(llm,prompt)\n",
    "rag_chain=create_retrieval_chain(retriever,question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Myopia, or nearsightedness, is a refractive error where the eye focuses light in front of the retina instead of on it. This causes distant objects to appear blurry while close objects remain clear.  It can be corrected with glasses, contact lenses\n"
     ]
    }
   ],
   "source": [
    "response=rag_chain.invoke({\"input\" : \"What is Myopia?\"})\n",
    "print(response[\"answer\"],end=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG MODEL TREATED FOR MULTIPLE BOOKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "books = [\n",
    "    \"data/Medical_book.pdf\",\n",
    "    \"data/Human_Anatomy.pdf\",\n",
    "    \"data/Gray's anatomy for students.pdf\",\n",
    "    \"data/Clinically oriented anatomy.pdf\",\n",
    "    \"data\\harrison’s-principles-of-internal-medicine-21st-edition.pdf\"\n",
    "]\n",
    "data_books = []\n",
    "for book in books:\n",
    "    loader = PyPDFLoader(book)\n",
    "    data = loader.load()\n",
    "    data_books.extend(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector_store = FAISS.from_documents(data_books, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The eye is the organ of vision.  It contains receptors for vision and a refracting system that focuses light rays onto the retina.  The eyeball is protected by the orbit, formed by various bones.\n",
      " "
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "vector_store.save_local(\"faiss_index\")\n",
    "\n",
    "def query_rag_model(question: str):\n",
    "    retrieved_docs = vector_store.similarity_search(question)\n",
    "    docs_content = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\n",
    "        \"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, say that you don't know. Use three sentences maximum and keep the answer concise.\\n\\n{context}\"\n",
    "    )\n",
    "    human_message = HumanMessagePromptTemplate.from_template(\"{input}\")\n",
    "    chat_prompt = ChatPromptTemplate.from_messages([system_message, human_message])\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.2)\n",
    "    chain = LLMChain(llm=llm, prompt=chat_prompt)\n",
    "    inputs = {\"context\": docs_content, \"input\": question}\n",
    "    if inputs[\"input\"] ==\"\":\n",
    "        return f\"You haven't given a question please give a question.\"\n",
    "    else :\n",
    "        response = chain.run(inputs)\n",
    "        return response\n",
    "\n",
    "question = \"what is an eye?\"\n",
    "response = query_rag_model(question)\n",
    "print(response,end=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE ABOVE RAG MODEL WORKS ON LANGCHAIN AND GEMINI PRO VERSION 1.5 AND PYTHON VERSION 3.10.0 . THIS MODEL IS TREATED WITH 5 BOOKS OF THE HUMAN ANATOMY AND AS FAR IT HAS SHOWN 100% ACCURACY."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
